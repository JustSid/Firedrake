//
//  smp.cpp
//  Firedrake
//
//  Created by Sidney Just
//  Copyright (c) 2013 by Sidney Just
//  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated 
//  documentation files (the "Software"), to deal in the Software without restriction, including without limitation 
//  the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, 
//  and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
//  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, 
//  INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR 
//  PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE 
//  FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, 
//  ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
//

#include <kern/kprintf.h>
#include <kern/spinlock.h>
#include <libc/string.h>
#include <machine/port.h>
#include <machine/cme.h>
#include <machine/gdt.h>
#include "smp.h"

extern "C" void smp_rendezvous_point();
extern "C" uintptr_t smp_bootstrap_begin;
extern "C" uintptr_t smp_bootstrap_end;
extern "C" uint32_t *_kernel_page_directory;

static spinlock_t _smp_rendezvous_lock = SPINLOCK_INIT;
static size_t _smp_ticks = 0;

#define SMP_PHYSICAL_CODE 0x7000
#define SMP_PHYSICAL_GDT  0x8000

/*
	smp_entry_bitmap uses the following code (generated by nasm)
	offsets and targets are patched up later

	00000000  FA                  cli
	00000001  0F 01 16 00 80      lgdt [0x8000]
	00000006  0F 20 C0            mov eax,cr0
	00000009  66 83 C8 01         or eax,byte +0x1
	0000000D  0F 22 C0            mov cr0,eax
	00000010  EA 00 00 08 00      jmp word 0x8:0x0000
*/

static uint8_t smp_entry_bitmap[] = {
	0xfa,
	0x0f, 0x01, 0x16, 0x00, 0x80,
	0x0f, 0x20, 0xc0,
	0x66, 0x83, 0xc8, 0x01,
	0x0f, 0x22, 0xc0,
	0xea, 0x00, 0x00, 0x08, 0x00
};

uint32_t smp_clock_tick(uint32_t esp, __unused cpu_t *cpu)
{
	_smp_ticks ++;
	return esp;
}



void smp_rendezvous_fail()
{
	sti();
	spinlock_unlock(&_smp_rendezvous_lock);

	while(1)
		cpu_halt();
}

void smp_rendezvous_point()
{
	spinlock_lock(&_smp_rendezvous_lock);

	// Activate the kernel directory and virtual memory
	uint32_t cr0;
	__asm__ volatile("mov %0, %%cr3" : : "r" (reinterpret_cast<uint32_t>(_kernel_page_directory)));
	__asm__ volatile("mov %%cr0, %0" : "=r" (cr0));
	__asm__ volatile("mov %0, %%cr0" : : "r" (cr0 | (1 << 31)));

	// Bootstrap Interrupts
	kern_return_t result = ir::init_application_cpu();

	if(result != KERN_SUCCESS)
		smp_rendezvous_fail();
	
	cpu_t *cpu = cpu_get_current_cpu();

	if(cpu->flags & CPU_FLAG_TIMEDOUT)
	{
		// Well, too late...
		smp_rendezvous_fail();
	}

	cpu->flags |= CPU_FLAG_RUNNING;

	spinlock_unlock(&_smp_rendezvous_lock);

	// Wait for work. The CPU will receive an IPI once the kernel is ready to start scheduling
	// this will automatically switch stacks and stop this thread of execution
	while(1)
		cpu_halt();
}

void smp_kickoff_cpu(cpu_t *cpu)
{
	uint32_t vector = APIC_ICR_DM_INIT | APIC_ICR_LV_ASSERT;
	ir::apic_send_ipi(0x0f, cpu, vector);

	// Wait 10ms for the CPU to initialize
	size_t ticksEnd = _smp_ticks + 1;
	while(_smp_ticks <= ticksEnd)
		cpu_halt();

	vector = ((SMP_PHYSICAL_CODE / 0x1000) & 0xff) | APIC_ICR_DSS_OTHERS | APIC_ICR_DM_STARTUP | APIC_ICR_LV_ASSERT;
	ir::apic_send_ipi(0x0, cpu, vector);

	// Wait up to 100ms for the rendezvous to happen
	ticksEnd = _smp_ticks + 10;
	while(_smp_ticks <= ticksEnd)
	{
		cpu_halt();

		if(spinlock_try_lock(&_smp_rendezvous_lock))
		{
			if(cpu->flags & CPU_FLAG_RUNNING)
			{
				spinlock_unlock(&_smp_rendezvous_lock);
				break;
			}

			spinlock_unlock(&_smp_rendezvous_lock);
		}
	}

	// Synchronize with the CPU to avoid race conditions
	spinlock_lock(&_smp_rendezvous_lock);

	if(!cpu->flags & CPU_FLAG_RUNNING)
		cpu->flags |= CPU_FLAG_TIMEDOUT;

	spinlock_unlock(&_smp_rendezvous_lock);
}

void smp_kickoff()
{
	// Set up the SMP timer used to keep track of timeouts
	// We use the old PIT at 100hz
	ir::apic_ioapic_mask_interrupt(0x20, false);
	ir::set_interrupt_handler(0x20, &smp_clock_tick);

	int divisor = 11931;
	outb(0x43, 0x36);
	outb(0x40, divisor & 0xff);
	outb(0x40, divisor >> 8);

	// Start up all CPUs
	size_t count = cpu_get_cpu_count();
	for(size_t i = 0; i < count; i ++)
	{
		cpu_t *cpu = cpu_get_cpu_with_id(i);
		if(cpu->flags & CPU_FLAG_BOOTSTRAP)
			continue;

		smp_kickoff_cpu(cpu);
	}

	ir::set_interrupt_handler(0x20, nullptr);
	ir::apic_ioapic_mask_interrupt(0x20, true);
}

void smp_forge_gdt(uint8_t *buffer)
{
	struct 
	{
		uint16_t limit;
		void *pointer;
	} __attribute__((packed)) gdtp;

	gdtp.limit   = 0x18;
	gdtp.pointer = reinterpret_cast<void *>(SMP_PHYSICAL_GDT + sizeof(gdtp));

	memcpy(buffer, &gdtp, sizeof(gdtp));

	uint64_t *gdt = reinterpret_cast<uint64_t *>(buffer + sizeof(gdtp));

	gdt_set_entry(gdt, 0, 0x0, 0x0, 0);
	gdt_set_entry(gdt, 1, 0x0, 0xffffffff, GDT_FLAG_SEGMENT | GDT_FLAG_32_BIT | GDT_FLAG_CODESEG | GDT_FLAG_4K | GDT_FLAG_PRESENT);
	gdt_set_entry(gdt, 2, 0x0, 0xffffffff, GDT_FLAG_SEGMENT | GDT_FLAG_32_BIT | GDT_FLAG_DATASEG | GDT_FLAG_4K | GDT_FLAG_PRESENT);
}

kern_return_t smp_init()
{
	// Get space to set up the protected mode GDT and the bootstrapping code
	uint8_t *bootstrapBegin = reinterpret_cast<uint8_t *>(&smp_bootstrap_begin);
	uint8_t *bootstrapEnd   = reinterpret_cast<uint8_t *>(&smp_bootstrap_end);

	size_t size  = (bootstrapEnd - bootstrapBegin) + sizeof(smp_entry_bitmap);
	size_t pages = VM_PAGE_COUNT(size) + 1;

	kern_return_t result;
	vm_address_t vaddress;

	if((result = vm::get_kernel_directory()->alloc(vaddress, SMP_PHYSICAL_CODE, pages, VM_FLAGS_KERNEL)) != KERN_SUCCESS)
	{
		kprintf("failed to allocate virtual memory");
		return result;
	}

	// Copy the bootstrapping code and set up the GDT
	uint8_t *buffer = reinterpret_cast<uint8_t *>(vaddress);	
	smp_forge_gdt(buffer + VM_PAGE_SIZE);

	memcpy(buffer, smp_entry_bitmap, sizeof(smp_entry_bitmap));
	memcpy(buffer + sizeof(smp_entry_bitmap), bootstrapBegin, size);

	// Fix up offsets
	cme_fix_ljump16(buffer, size, reinterpret_cast<void *>(SMP_PHYSICAL_CODE + sizeof(smp_entry_bitmap)));

	// Unmap the buffer and kick off the CPUs
	vm::get_kernel_directory()->free(vaddress, pages);
	smp_kickoff();

	// Debug output
	size_t count = cpu_get_cpu_count();
	for(size_t i = 0; i < count; i ++)
	{
		cpu_t *cpu = cpu_get_cpu_with_id(i);
		kprintf("%c", (cpu->flags & CPU_FLAG_RUNNING) ? (cpu->flags & CPU_FLAG_BOOTSTRAP) ? 'B' : 'R' : 'T');
	}

	return KERN_SUCCESS;
}
